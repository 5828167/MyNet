{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x):\n",
    "    lengths2 = x.pow(2).sum(dim=2)\n",
    "    lengths = lengths2.sqrt()\n",
    "    x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgreementRouting(nn.Module):\n",
    "    def __init__(self, input_caps, output_caps, n_iterations):\n",
    "        super(AgreementRouting, self).__init__()\n",
    "        self.n_iterations = n_iterations\n",
    "        self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))\n",
    "\n",
    "    def forward(self, u_predict):\n",
    "        batch_size, input_caps, output_caps, output_dim = u_predict.size()\n",
    "\n",
    "        c = F.softmax(self.b)\n",
    "        s = (c.unsqueeze(2) * u_predict).sum(dim=1)\n",
    "        v = squash(s)\n",
    "\n",
    "        if self.n_iterations > 0:\n",
    "            b_batch = self.b.expand((batch_size, input_caps, output_caps))\n",
    "            for r in range(self.n_iterations):\n",
    "                v = v.unsqueeze(1)\n",
    "                b_batch = b_batch + (u_predict * v).sum(-1)\n",
    "\n",
    "                c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
    "                s = (c * u_predict).sum(dim=1)\n",
    "                v = squash(s)\n",
    "\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode_layer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, output_caps):\n",
    "        super(Encode_layer, self).__init__()\n",
    "        \n",
    "        self.layer = nn.Linear(input_dim, output_dim*output_caps)\n",
    "        self.output_dim = output_dim\n",
    "        self.output_caps = output_caps\n",
    "        \n",
    "    def forward(self, input) : \n",
    "        output = self.layer(input)\n",
    "        output = F.relu(output)\n",
    "        output = output.view(output.shape[0], self.output_caps, self.output_dim)\n",
    "        output = squash(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron_layer(nn.Module):\n",
    "    def __init__(self, input_neurons, input_dim, output_dim, output_neurons, routing):\n",
    "        super(Neuron_layer, self).__init__()\n",
    "        self.input_neurons = input_neurons\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.output_neurons = output_neurons\n",
    "        self.routing = routing\n",
    "        self.weights = nn.Parameter(torch.Tensor(input_neurons, input_dim, output_neurons * output_dim))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.input_neurons)\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input = input.unsqueeze(2)\n",
    "        predict = input.matmul(self.weights)\n",
    "        predict = predict.view(predict.size(0), self.input_neurons, self.output_neurons, self.output_dim)\n",
    "        v = self.routing(predict)\n",
    "        \n",
    "        return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learning(nn.Module) :\n",
    "    def __init__(self, routing_iterations) :\n",
    "        super(Learning, self).__init__()\n",
    "        \n",
    "        self.network1 = Encode_layer(784, 128, 4)\n",
    "        \n",
    "        routing_module1 = AgreementRouting(4, 3, routing_iterations)\n",
    "        \n",
    "        self.network2 = Neuron_layer(4, 128, 32, 3, routing_module1)\n",
    "        \n",
    "        routing_module2 = AgreementRouting(3, 10, routing_iterations)\n",
    "        \n",
    "        self.network3 = Neuron_layer(3, 32, 16, 10, routing_module2)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output1 = self.network1(input)\n",
    "        output2 = self.network2(output1)\n",
    "        output3 = self.network3(output2)\n",
    "        \n",
    "        probs = output3.pow(2).sum(dim=2).sqrt()\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Learning(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_pos, m_neg, lambda_):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, lengths, targets, size_average=True):\n",
    "        t = torch.zeros(lengths.size()).long()\n",
    "        if targets.is_cuda:\n",
    "            t = t.cuda()\n",
    "        t = t.scatter_(1, targets.data.view(-1, 1), 1)\n",
    "        targets = Variable(t)\n",
    "        losses = targets.float() * F.relu(self.m_pos - lengths).pow(2) + \\\n",
    "                 self.lambda_ * (1. - targets.float()) * F.relu(lengths - self.m_neg).pow(2)\n",
    "        return losses.mean() if size_average else losses.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15, min_lr=1e-6)\n",
    "\n",
    "loss_fn = MarginLoss(0.9, 0.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct=0.\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data.view(data.shape[0], -1)), Variable(target, requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        probs= model(data)\n",
    "        \n",
    "        loss = loss_fn(probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            \n",
    "        pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    print('Accuracy : {:.2f}%'.format(100. * correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.079527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1000/60000 (2%)]\tLoss: 0.075467\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 0.071799\n",
      "Train Epoch: 0 [3000/60000 (5%)]\tLoss: 0.066443\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.062011\n",
      "Train Epoch: 0 [5000/60000 (8%)]\tLoss: 0.055087\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.043378\n",
      "Train Epoch: 0 [7000/60000 (12%)]\tLoss: 0.037825\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.031055\n",
      "Train Epoch: 0 [9000/60000 (15%)]\tLoss: 0.025224\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.024598\n",
      "Train Epoch: 0 [11000/60000 (18%)]\tLoss: 0.021841\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.019545\n",
      "Train Epoch: 0 [13000/60000 (22%)]\tLoss: 0.017041\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.015714\n",
      "Train Epoch: 0 [15000/60000 (25%)]\tLoss: 0.016449\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.011405\n",
      "Train Epoch: 0 [17000/60000 (28%)]\tLoss: 0.021132\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.016013\n",
      "Train Epoch: 0 [19000/60000 (32%)]\tLoss: 0.011035\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.016704\n",
      "Train Epoch: 0 [21000/60000 (35%)]\tLoss: 0.016430\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.008729\n",
      "Train Epoch: 0 [23000/60000 (38%)]\tLoss: 0.011738\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.011977\n",
      "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 0.011795\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.009453\n",
      "Train Epoch: 0 [27000/60000 (45%)]\tLoss: 0.010082\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.006776\n",
      "Train Epoch: 0 [29000/60000 (48%)]\tLoss: 0.010533\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.007963\n",
      "Train Epoch: 0 [31000/60000 (52%)]\tLoss: 0.006756\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.006760\n",
      "Train Epoch: 0 [33000/60000 (55%)]\tLoss: 0.006517\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.010155\n",
      "Train Epoch: 0 [35000/60000 (58%)]\tLoss: 0.006240\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.007494\n",
      "Train Epoch: 0 [37000/60000 (62%)]\tLoss: 0.009397\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.008060\n",
      "Train Epoch: 0 [39000/60000 (65%)]\tLoss: 0.008786\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.005862\n",
      "Train Epoch: 0 [41000/60000 (68%)]\tLoss: 0.004368\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.009904\n",
      "Train Epoch: 0 [43000/60000 (72%)]\tLoss: 0.007491\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.007796\n",
      "Train Epoch: 0 [45000/60000 (75%)]\tLoss: 0.005690\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.006881\n",
      "Train Epoch: 0 [47000/60000 (78%)]\tLoss: 0.007860\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.004460\n",
      "Train Epoch: 0 [49000/60000 (82%)]\tLoss: 0.005707\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.005244\n",
      "Train Epoch: 0 [51000/60000 (85%)]\tLoss: 0.005208\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.003149\n",
      "Train Epoch: 0 [53000/60000 (88%)]\tLoss: 0.006980\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.007009\n",
      "Train Epoch: 0 [55000/60000 (92%)]\tLoss: 0.004820\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.005719\n",
      "Train Epoch: 0 [57000/60000 (95%)]\tLoss: 0.005678\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.003875\n",
      "Train Epoch: 0 [59000/60000 (98%)]\tLoss: 0.003581\n",
      "Accuracy : 82.44%\n",
      "1\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.004930\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.005756\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.005564\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.002579\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.003544\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.005942\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.005105\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.002070\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.006251\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.006151\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.003840\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.005885\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.004023\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.007355\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.002752\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.005265\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.001404\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.004253\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.003407\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.004083\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.003291\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.004275\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.003984\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.006003\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.003611\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.002814\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.004712\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.003758\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.003890\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.004455\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.004270\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.004322\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.003373\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.003468\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.004916\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.004408\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.004842\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.003122\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.005079\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.003337\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.004114\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.005885\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.002161\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.003933\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.004381\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.005315\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.002320\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.005460\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.001586\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.003925\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.004748\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.005881\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.002250\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.003994\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.004217\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.004534\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.004439\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.002274\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.001544\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.005082\n",
      "Accuracy : 94.91%\n",
      "2\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.004367\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.003106\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.002038\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.004418\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.003275\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.002672\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.001799\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.003479\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.000805\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.002845\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.002764\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.003557\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.001862\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.002627\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.003681\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.002309\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.001812\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.004620\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.003673\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.004297\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.005776\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.003330\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.002153\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.001998\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.004896\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.004348\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.003626\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.004638\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.002513\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.001617\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.003459\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.004967\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001969\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.001161\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.005050\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.003050\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.002664\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.003870\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.003543\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.001615\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.003226\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.005520\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.002697\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.003687\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.002491\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.002783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.003492\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.003725\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.005688\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.003397\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.002842\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.002145\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.003693\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.002976\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.002253\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.000998\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.003396\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.004515\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.001794\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.003284\n",
      "Accuracy : 96.44%\n",
      "3\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001247\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.001788\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.004035\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.002603\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.002459\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.001946\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.000906\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.002170\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.001655\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.002190\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.004091\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.001713\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.003137\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.002429\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.001453\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.001275\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.002359\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.003375\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.001872\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.002672\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.003571\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.000556\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.002105\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.003054\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.001623\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.001723\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.000602\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.002496\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.002106\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.003409\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.000725\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.002269\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.006965\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.001424\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.001079\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.001924\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.000905\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.002407\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.003035\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.001027\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.003025\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.001334\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.001581\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.001131\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.002780\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.004176\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.003452\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.004172\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.001946\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.003722\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.001847\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.001065\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.002355\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.001824\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.003028\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.001688\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.001296\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.001940\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.000510\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.002771\n",
      "Accuracy : 97.31%\n",
      "4\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.002790\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.000958\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.001541\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.002752\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.002722\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.002006\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.001258\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.002273\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.000643\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.002410\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.000697\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.001010\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.002430\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.003212\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.002155\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.001460\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.003283\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.001548\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.002614\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.001147\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.000729\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.000750\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.002252\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.001676\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.001638\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.002610\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.000704\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.003563\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.002867\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.002012\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.001058\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.002227\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001004\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.000680\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.002484\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.001369\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.002128\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.003155\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.000921\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.002965\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.001864\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.001975\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.000570\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.003322\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.002676\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.001351\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.003143\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.001842\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.003716\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.002218\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.000591\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.000856\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.002003\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.000446\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.001108\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.000528\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.001470\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.002516\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.001025\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.002200\n",
      "Accuracy : 97.81%\n",
      "5\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001522\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.002676\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.003013\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.001748\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.001520\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.000686\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.000672\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.001214\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.001688\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.001554\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.001028\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.000918\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.002660\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.001797\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.002484\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.002359\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.000631\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.000743\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.001173\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.001750\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.001181\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.001841\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.002412\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.000983\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.000356\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.001494\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.001594\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.000880\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.001968\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.002346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.000934\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.001396\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.003024\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.000481\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.001021\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.001321\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.001648\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.000991\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.002110\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.001627\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000328\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.000533\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.000609\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.001870\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.001672\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.000588\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.001030\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.000916\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.001894\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.001477\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.001133\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.001882\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.002752\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.002848\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.002177\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.001035\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.001867\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.000967\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.002258\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.000899\n",
      "Accuracy : 98.23%\n",
      "6\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001047\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.001387\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.001286\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.001473\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.001948\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.000950\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.001374\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.001053\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.000921\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.001596\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.002823\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.000313\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.001901\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.001218\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.000143\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.002058\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.000841\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.001630\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.002912\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.002668\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.001787\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.000969\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.000963\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.001600\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.000309\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.001674\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.001191\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.000935\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.002098\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.001380\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.000381\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.001098\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.002043\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.000896\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.000909\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.003293\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.001613\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.001600\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.000644\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.002272\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.000479\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.000330\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.001021\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.000081\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.001466\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.001578\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.001684\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.001379\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.002552\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.000306\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.002746\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.001541\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.001013\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.002188\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.000693\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.000447\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.000653\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.000434\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.002200\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.000681\n",
      "Accuracy : 98.56%\n",
      "7\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001372\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.001617\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.000474\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.000544\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.001424\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.000699\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.000931\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.001006\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.000110\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.001136\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.000535\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.001842\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.001467\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.000845\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.001344\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.001570\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.002479\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.002227\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.001061\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.001010\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.001249\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.000309\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.000419\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.000772\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.001092\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.000693\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.000871\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.001893\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.001387\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.000294\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.000266\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.000795\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001174\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.001392\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.000270\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.001228\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.000997\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.001681\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.000398\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.000062\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.000085\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.001529\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.002105\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.000620\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.001816\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.001368\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.000386\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.001383\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.002479\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.000489\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.000769\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.000925\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.001649\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.000171\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.000495\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.001318\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.000692\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.002318\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.000961\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.000562\n",
      "Accuracy : 98.86%\n",
      "8\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000395\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.000975\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.002016\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.000233\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.001237\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.002057\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.002031\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.000504\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.000949\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.001336\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.000994\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.000235\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.002003\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.000224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.001142\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.000810\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.000410\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.000456\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.001345\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.001107\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.000237\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.000715\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.000190\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.001752\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.001584\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.002779\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.002098\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.000699\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.000748\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.001013\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.000833\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.001050\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000456\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.000843\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.001643\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.000683\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.000240\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.002510\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.000943\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.000590\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.001298\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.000320\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.000398\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.001949\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.000300\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.002551\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.001402\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.000293\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001775\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.001020\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.002125\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.000421\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.000116\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.000147\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.001178\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.000181\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.002013\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.000980\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.002082\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.001704\n",
      "Accuracy : 99.03%\n",
      "9\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000294\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.000056\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.001035\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.000433\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.000161\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.000080\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.001099\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.000412\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.000264\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.001370\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.000367\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.000791\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.001056\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.000069\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.000895\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.002615\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.001273\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.001028\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.000482\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.000252\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.000132\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.000850\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.000349\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.001217\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.001816\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.001379\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.000474\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.000390\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.000428\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.000196\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.002370\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.000493\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.001952\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.000902\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.000434\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.000434\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.000283\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.000064\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.000355\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.000100\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.001737\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.000276\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.001090\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.001026\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.001331\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.000618\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.002083\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.000570\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.003334\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.000156\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.001173\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.000749\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.000255\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.000391\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.001317\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.000854\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.002600\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.000184\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.000443\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.000067\n",
      "Accuracy : 99.23%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10) :\n",
    "    print(epoch)\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "total=0\n",
    "correct=0.\n",
    "#batch size 다를 땐 테스트가 안 됌?\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(images.shape[0], -1))\n",
    "    outputs= model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=1, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/suii/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "2 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :5\n",
      "\n",
      "3 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :8\n",
      "\n",
      "4 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :2\n",
      "\n",
      "5 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "6 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :7\n",
      "\n",
      "7 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :8\n",
      "\n",
      "8 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :3\n",
      "\n",
      "9 th example \n",
      "True value: 5\n",
      "Predicted value : 6\n",
      "Adversarial :6\n",
      "\n",
      "10 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :4\n",
      "\n",
      "11 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :0\n",
      "\n",
      "12 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :8\n",
      "\n",
      "13 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :4\n",
      "\n",
      "14 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :7\n",
      "\n",
      "15 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :3\n",
      "\n",
      "16 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :3\n",
      "\n",
      "17 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :7\n",
      "\n",
      "18 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "19 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "20 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "21 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :7\n",
      "\n",
      "22 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :5\n",
      "\n",
      "23 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :7\n",
      "\n",
      "24 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :3\n",
      "\n",
      "25 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "26 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :0\n",
      "\n",
      "27 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "28 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "29 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :0\n",
      "\n",
      "30 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :3\n",
      "\n",
      "31 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "32 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :3\n",
      "\n",
      "33 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "34 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :0\n",
      "\n",
      "35 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "36 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :5\n",
      "\n",
      "37 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "38 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :8\n",
      "\n",
      "39 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :5\n",
      "\n",
      "40 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :3\n",
      "\n",
      "41 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :3\n",
      "\n",
      "42 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :3\n",
      "\n",
      "43 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :9\n",
      "\n",
      "44 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :5\n",
      "\n",
      "45 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "46 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :3\n",
      "\n",
      "47 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :8\n",
      "\n",
      "48 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :6\n",
      "\n",
      "49 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :4\n",
      "\n",
      "50 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "51 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :5\n",
      "\n",
      "52 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :3\n",
      "\n",
      "53 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :5\n",
      "\n",
      "54 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :3\n",
      "\n",
      "55 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :2\n",
      "\n",
      "56 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :6\n",
      "\n",
      "57 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :7\n",
      "\n",
      "58 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :7\n",
      "\n",
      "59 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :4\n",
      "\n",
      "60 th example \n",
      "True value: 5\n",
      "Predicted value : 5\n",
      "Adversarial :8\n",
      "\n",
      "61 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :3\n",
      "\n",
      "62 th example \n",
      "True value: 8\n",
      "Predicted value : 8\n",
      "Adversarial :2\n",
      "\n",
      "63 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :8\n",
      "\n",
      "64 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :2\n",
      "\n",
      "65 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :3\n",
      "\n",
      "66 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :5\n",
      "\n",
      "67 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :2\n",
      "\n",
      "68 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :9\n",
      "\n",
      "69 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "70 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :5\n",
      "\n",
      "71 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :7\n",
      "\n",
      "72 th example \n",
      "True value: 0\n",
      "Predicted value : 0\n",
      "Adversarial :0\n",
      "\n",
      "73 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :3\n",
      "\n",
      "74 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :7\n",
      "\n",
      "75 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :9\n",
      "\n",
      "76 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "77 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :8\n",
      "\n",
      "78 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :2\n",
      "\n",
      "79 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :8\n",
      "\n",
      "80 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :7\n",
      "\n",
      "81 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :9\n",
      "\n",
      "82 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :2\n",
      "\n",
      "83 th example \n",
      "True value: 2\n",
      "Predicted value : 2\n",
      "Adversarial :2\n",
      "\n",
      "84 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :5\n",
      "\n",
      "85 th example \n",
      "True value: 8\n",
      "Predicted value : 8\n",
      "Adversarial :8\n",
      "\n",
      "86 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :8\n",
      "\n",
      "87 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :3\n",
      "\n",
      "88 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :5\n",
      "\n",
      "89 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :2\n",
      "\n",
      "90 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :8\n",
      "\n",
      "91 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :8\n",
      "\n",
      "92 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :2\n",
      "\n",
      "93 th example \n",
      "True value: 9\n",
      "Predicted value : 9\n",
      "Adversarial :2\n",
      "\n",
      "94 th example \n",
      "True value: 3\n",
      "Predicted value : 3\n",
      "Adversarial :9\n",
      "\n",
      "95 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :8\n",
      "\n",
      "96 th example \n",
      "True value: 4\n",
      "Predicted value : 4\n",
      "Adversarial :9\n",
      "\n",
      "97 th example \n",
      "True value: 1\n",
      "Predicted value : 1\n",
      "Adversarial :9\n",
      "\n",
      "98 th example \n",
      "True value: 7\n",
      "Predicted value : 7\n",
      "Adversarial :2\n",
      "\n",
      "99 th example \n",
      "True value: 6\n",
      "Predicted value : 6\n",
      "Adversarial :0\n",
      "\n",
      "Accuracy of test_model : 1.000 , Adversarials : 86.000\n"
     ]
    }
   ],
   "source": [
    "dummy=1\n",
    "s=0.\n",
    "t=0.\n",
    "\n",
    "\n",
    "for (x, y) in adv_test_loader :\n",
    "    x, y = Variable(x, requires_grad=True), Variable(y, requires_grad=False)\n",
    "    probs= model(x.view(x.shape[0], -1))\n",
    "    y_pred = np.argmax(probs.data.numpy())\n",
    "    loss = nn.CrossEntropyLoss()(probs, y)\n",
    "    loss.backward()\n",
    "    epsilon = 0.1 \n",
    "    x_grad   = torch.sign(x.grad.data)\n",
    "    x_adversarial = torch.clamp(x.data + epsilon * x_grad, 0, 1)\n",
    "    adversarial_probs= model(Variable(x_adversarial).view(x.shape[0], -1))\n",
    "    y_pred_adversarial = np.argmax(adversarial_probs.data.numpy())\n",
    "    \n",
    "    print(\"{0} th example \".format(dummy))\n",
    "    print (\"True value: \"+ str(y.data.numpy()[0])+\"\\nPredicted value : \"+str(y_pred)+ \"\\nAdversarial :\" + str(y_pred_adversarial)+\"\\n\" )\n",
    "    \n",
    "    dummy+=1\n",
    "    \n",
    "    if y.data.numpy()[0]!=y_pred :\n",
    "        t+=1\n",
    "    \n",
    "    if y_pred!=y_pred_adversarial :\n",
    "        s+=1\n",
    "    if dummy==100:\n",
    "        break\n",
    "        \n",
    "print(\"Accuracy of test_model : {0:.3f} , Adversarials : {1:.3f}\".format((t/dummy)*100, (s/dummy)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
